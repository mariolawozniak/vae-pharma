{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tensorflow import keras\n",
    "from tdc.single_pred.adme import ADME\n",
    "from tdc import Evaluator\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "from rdkit.Chem import BondType\n",
    "from rdkit.Chem.Draw import MolsToGridImage\n",
    "from torch import tensor\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "IPythonConsole.molSize = 250,250\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 249455 entries, 0 to 249454\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   smiles  249455 non-null  object \n",
      " 1   logP    249455 non-null  float64\n",
      " 2   qed     249455 non-null  float64\n",
      " 3   SAS     249455 non-null  float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "csv_path = keras.utils.get_file(\n",
    "    \"250k_rndm_zinc_drugs_clean_3.csv\",\n",
    "    \"https://raw.githubusercontent.com/aspuru-guzik-group/chemical_vae/master/models/zinc_properties/250k_rndm_zinc_drugs_clean_3.csv\",\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\"~/.keras/datasets/250k_rndm_zinc_drugs_clean_3.csv\")\n",
    "df[\"smiles\"] = df[\"smiles\"].apply(lambda s: s.replace(\"\\n\", \"\"))\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMILE_CHARSET = '[\"C\", \"B\", \"F\", \"I\", \"H\", \"O\", \"N\", \"S\", \"P\", \"Cl\", \"Br\", None]'  #wyrzucić B, Br,  P, I\n",
    "\n",
    "bond_mapping = {None: 0, \"SINGLE\": 1, \"DOUBLE\": 2, \"TRIPLE\": 3, \"AROMATIC\": 4}\n",
    "bond_mapping.update(\n",
    "    {0: None, 1: BondType.SINGLE, 2: BondType.DOUBLE, 3: BondType.TRIPLE, 4: BondType.AROMATIC}\n",
    ")\n",
    "SMILE_CHARSET = ast.literal_eval(SMILE_CHARSET)\n",
    "MAX_BONDNUM = 150\n",
    "MAX_MOLSIZE = 64 #max(df[\"smiles\"].str.len())\n",
    "SMILE_to_index = dict((c, i) for i, c in enumerate(SMILE_CHARSET))\n",
    "index_to_SMILE = dict((i, c) for i, c in enumerate(SMILE_CHARSET))\n",
    "atom_mapping = dict(SMILE_to_index)\n",
    "atom_mapping.update(index_to_SMILE)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 500\n",
    "\n",
    "VAE_LR = 5e-4\n",
    "NUM_ATOMS = 32  # Maximum number of atoms\n",
    "\n",
    "ATOM_DIM = len(SMILE_CHARSET)  # Number of atom types\n",
    "BOND_DIM = 5  # Number of bond types\n",
    "LATENT_DIM = 128  # Size of the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_idx_to_adj(edge_index, edges_attr):\n",
    "    #print(edges_attr)\n",
    "    adj = np.zeros((NUM_ATOMS, NUM_ATOMS))\n",
    "    attr_matrix = np.zeros((NUM_ATOMS, NUM_ATOMS, BOND_DIM))\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        k = edge_index[0][i]\n",
    "        j = edge_index[1][i]\n",
    "        adj[k][j] = 1\n",
    "        attr_matrix[k][j] = edges_attr[i]\n",
    "    return torch.tensor(adj), torch.tensor(attr_matrix)\n",
    "\n",
    "def batch_edge_idx_to_adj(edge_index, edges_attr):\n",
    "    adj = np.zeros((BATCH_SIZE*NUM_ATOMS, BATCH_SIZE*NUM_ATOMS))\n",
    "    attr_matrix = np.zeros((BATCH_SIZE*NUM_ATOMS,BATCH_SIZE*NUM_ATOMS, BOND_DIM))\n",
    "    adj_reduced = np.zeros((0, NUM_ATOMS))\n",
    "    attr_reduced = np.zeros((0, NUM_ATOMS, BOND_DIM))\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        k = edge_index[0][i]\n",
    "        j = edge_index[1][i]\n",
    "        adj[k][j] = 1\n",
    "        attr_matrix[k][j] = edges_attr[i]\n",
    "    for i in range(BATCH_SIZE):\n",
    "        #print(adj.shape, (adj[i*NUM_ATOMS:(i+1)*NUM_ATOMS,i*NUM_ATOMS:(i+1)*NUM_ATOMS]).shape)\n",
    "        adj_reduced = np.concatenate([adj_reduced, adj[i*NUM_ATOMS:(i+1)*NUM_ATOMS,i*NUM_ATOMS:(i+1)*NUM_ATOMS]], axis=0)\n",
    "        attr_reduced = np.concatenate([attr_reduced, attr_matrix[i*NUM_ATOMS:(i+1)*NUM_ATOMS,i*NUM_ATOMS:(i+1)*NUM_ATOMS,:]], axis=0)\n",
    "    return torch.tensor(adj_reduced), torch.tensor(attr_reduced)\n",
    "\n",
    "def molecule_to_graph(molecule):\n",
    "    # Converts SMILES to molecule object\n",
    "    \n",
    "    mol_atoms = molecule.GetNumAtoms()    # Initialize adjacency and feature tensor\n",
    "    num_of_bonds = molecule.GetNumBonds()\n",
    "    edge_index = [[],[]]\n",
    "    edge_features = []\n",
    "    adj_mat = np.zeros((NUM_ATOMS, ATOM_DIM))\n",
    "    \n",
    "    features = np.zeros((NUM_ATOMS, ATOM_DIM))\n",
    "\n",
    "    # loop over each atom in molecule\n",
    "    for atom in molecule.GetAtoms():\n",
    "        atom_idx = atom.GetIdx()\n",
    "        atom_type = atom_mapping[atom.GetSymbol()]\n",
    "        atomic_num = atom.GetAtomicNum()\n",
    "        degree = atom.GetDegree()\n",
    "        features[atom_idx] = np.eye(ATOM_DIM)[atom_type] #np.concatenate((np.eye(ATOM_DIM)[atom_type][:-2], chem_features), axis=0)\n",
    "    for i in range(mol_atoms, NUM_ATOMS):\n",
    "        features[i][ATOM_DIM-1] = 1\n",
    "        edge_index[0].append(i)\n",
    "        edge_index[1].append(i)\n",
    "        edge_embbeding = list(np.eye(BOND_DIM)[BOND_DIM-1])\n",
    "        edge_features.append(edge_embbeding)\n",
    "        # loop over one-hop neighbors\n",
    "    for bond in molecule.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        bond_type_idx = bond_mapping[bond.GetBondType().name]\n",
    "        edge_index[0] = list(np.append(edge_index[0], [i, j]))\n",
    "        edge_index[1] = list(np.append(edge_index[1], [j, i]))\n",
    "        edge_embbeding = list(np.eye(BOND_DIM)[bond_type_idx])\n",
    "        edge_features.append(edge_embbeding)\n",
    "        edge_features.append(edge_embbeding)\n",
    "    return tensor(features), tensor(edge_index), tensor(edge_features)\n",
    "\n",
    "\n",
    "def graph_to_molecule(graph):  # for edges in adjacency matrix format\n",
    "    features, adjacency, edge_features = graph\n",
    "\n",
    "    if adjacency.shape[0] == 2:\n",
    "       adjacency, edge_features = batch_edge_idx_to_adj(adjacency, edge_features)\n",
    "    #print(features, adjacency, edge_features)\n",
    "    # RWMol is a molecule object intended to be edited\n",
    "    molecule = Chem.RWMol()\n",
    "    for i in range(len(adjacency)):\n",
    "        adjacency[i][i] = 0\n",
    "\n",
    "    # Remove \"no atoms\" & atoms with no bonds\n",
    "    mol_idx_to_graph_idx = np.where(\n",
    "        (np.argmax(features, axis=1) != ATOM_DIM - 1)\n",
    "        & (adjacency.sum(axis=1) != 0)\n",
    "    )\n",
    "    mol_idx_to_graph_idx = np.squeeze(mol_idx_to_graph_idx)\n",
    "\n",
    "    graph_idx_to_mol_idx = np.full_like([], fill_value=-1, shape=NUM_ATOMS, dtype=int)\n",
    "    for mol_idx, graph_idx in enumerate(mol_idx_to_graph_idx):\n",
    "        graph_idx_to_mol_idx[graph_idx] = mol_idx\n",
    "    \n",
    "    for mol_idx, graph_idx in enumerate(mol_idx_to_graph_idx):\n",
    "        atom_type_idx = int(torch.argmax(features[graph_idx]))\n",
    "        atom = Chem.Atom(atom_mapping[atom_type_idx])\n",
    "        _ = molecule.AddAtom(atom)\n",
    "\n",
    "    for mol_idx_1, graph_idx_1 in enumerate(mol_idx_to_graph_idx):\n",
    "        for mol_idx_2, graph_idx_2 in enumerate(mol_idx_to_graph_idx):\n",
    "            if adjacency[graph_idx_1][graph_idx_2] > 0.6 and graph_idx_2 > graph_idx_1:\n",
    "                #print(edge_features[graph_idx_1][graph_idx_2])\n",
    "                edge_type_encoded = int(np.argmax(edge_features[graph_idx_1][graph_idx_2]))\n",
    "                #bond_type = bond_mapping[edge_type_encoded]       \n",
    "                if edge_type_encoded != 4: molecule.AddBond(int(mol_idx_1), int(mol_idx_2), Chem.BondType.SINGLE)\n",
    "\n",
    "    flag = Chem.SanitizeMol(molecule, catchErrors=True)\n",
    "\n",
    "    if flag != Chem.SanitizeFlags.SANITIZE_NONE:\n",
    "        print(\"Sth went wrong\")\n",
    "        return molecule\n",
    "    #print(\"OK\")\n",
    "    return molecule\n",
    "\n",
    "def adj_to_index(adj_matrix, attr_matrix):\n",
    "    edge_index=[[], []]\n",
    "    edge_attr = []\n",
    "    for i, row in enumerate(adj_matrix):\n",
    "        adj_matrix[i][i]=0 \n",
    "        for j in range(len(row)):\n",
    "            if row[j] == 1:\n",
    "                edge_index[0].append(i)\n",
    "                edge_index[1].append(j)\n",
    "                edge_embedding = attr_matrix[i][j]\n",
    "                edge_attr.append(edge_embedding)\n",
    "    return torch.tensor(edge_index), torch.tensor(edge_attr)\n",
    "\n",
    "\n",
    "def concat_features(features, edge_index, edges_attr):\n",
    "    if edges_attr.shape[1]==5:\n",
    "        edges_attr_3d = edge_idx_to_adj(edge_index, edges_attr)[1]\n",
    "        edges_adj = np.zeros((NUM_ATOMS, NUM_ATOMS), int)\n",
    "        for i in range(NUM_ATOMS):\n",
    "            for j in range(NUM_ATOMS):\n",
    "                edges_adj[i][j]= int(np.argmax(edges_attr_3d[i][j]))\n",
    "    else: \n",
    "        edges_adj = np.zeros((NUM_ATOMS, NUM_ATOMS), int)\n",
    "        for i in range(NUM_ATOMS):\n",
    "            for j in range(NUM_ATOMS):\n",
    "                edges_adj[i][j]= int(np.argmax(edges_attr[i][j]))\n",
    "    res = torch.cat((torch.Tensor(features), torch.Tensor(edges_adj)), dim=1)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "\n",
    "class Featurizer():\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "    def __call__(self, df):\n",
    "        graphs = []\n",
    "        labels = []\n",
    "        for i, row in df.iterrows():\n",
    "            smiles = row[\"smiles\"]\n",
    "            molecule = Chem.MolFromSmiles(smiles)\n",
    "            if molecule.GetNumAtoms() < 32:\n",
    "                features, edge_index, edge_attr = molecule_to_graph(molecule) \n",
    "                features = concat_features(features, edge_index, edge_attr)\n",
    "                graphs.append((features, edge_index, edge_attr))\n",
    "                labels.append(molecule)\n",
    "            \n",
    "        return [Data(\n",
    "            features=features.float(), \n",
    "            edge_index=edge_index.int(), \n",
    "            edge_attr=edge_attr.float(),\n",
    "            mol=labels)\n",
    "            for ((features, edge_index, edge_attr), labels) in zip(graphs, labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data, test_data = model_selection.train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = Featurizer()\n",
    "data_train = featurizer(train_data[:1024])\n",
    "data_val = featurizer(test_data[:128])\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(data_train, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(data_val, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature(input, t=1.0):\n",
    "  return input/t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_bin(edges_attr):\n",
    "    edges_adj = torch.zeros(size=(NUM_ATOMS, NUM_ATOMS))\n",
    "    for i in range(NUM_ATOMS):\n",
    "        for j in range(NUM_ATOMS):\n",
    "            if np.argmax(edges_attr[i][j]) > 0:\n",
    "                edges_adj[i][j] = 1\n",
    "    return edges_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "#import torch.nn.functional as F\n",
    "from torch.nn.functional import dropout, one_hot\n",
    "import torch\n",
    "\n",
    "\n",
    "HIDDEN_SIZE=512\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_size=HIDDEN_SIZE, atom_dim = ATOM_DIM, latent_dim=LATENT_DIM):\n",
    "        super(Encoder, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "\n",
    "        self.conv = [\n",
    "            GATConv(atom_dim+NUM_ATOMS, hidden_size),\n",
    "            GATConv(hidden_size, hidden_size),\n",
    "            GATConv(hidden_size, hidden_size),\n",
    "            GATConv(hidden_size, hidden_size),\n",
    "            GATConv(hidden_size, hidden_size),\n",
    "            GATConv(hidden_size, hidden_size),\n",
    "            GATConv(hidden_size, hidden_size),\n",
    "            GATConv(hidden_size, hidden_size),\n",
    "            GATConv(hidden_size, hidden_size),\n",
    "            GATConv(hidden_size, hidden_size)\n",
    "        ]\n",
    "        self.pooling = global_mean_pool\n",
    "        self.dense = [\n",
    "            torch.nn.Linear(in_features=hidden_size, out_features=hidden_size)\n",
    "        ]\n",
    "        self.mean = torch.nn.Linear(in_features=hidden_size, out_features=latent_dim)\n",
    "        self.std = torch.nn.Linear(in_features=hidden_size, out_features=latent_dim)\n",
    "        self.elu = torch.nn.ELU() \n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch): \n",
    "        for conv_layer in self.conv:\n",
    "            x = conv_layer(x, edge_index, edge_attr)\n",
    "            x = self.elu(x)    # definiować w konstruktorze\n",
    "        #print(batch)\n",
    "        #print(\"before pooling \", x.shape)\n",
    "        x = self.pooling(x, batch=batch) #, size = x.shape[1])#[0]\n",
    "        #print(\"after pooling \", x.shape)\n",
    "        #x = torch.flatten(x)\n",
    "       # print(\"after flattening \", x.shape)\n",
    "        for layer in self.dense:\n",
    "            x = layer(x)\n",
    "            x = self.elu(x)\n",
    "        #print(\"after densing \", x.shape)\n",
    "        mu, std = self.mean(x), self.std(x)\n",
    "        #print(\"mu, std: \", mu.shape, std.shape)\n",
    "        return mu, std\n",
    "    \n",
    "    def loss():\n",
    "        pass\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_size=HIDDEN_SIZE, atom_dim = ATOM_DIM, latent_dim=LATENT_DIM) -> None:\n",
    "        super(Decoder, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.decoding = [\n",
    "            torch.nn.Linear(in_features=latent_dim, out_features=int(NUM_ATOMS)*(int(ATOM_DIM)+5*NUM_ATOMS)),\n",
    "            torch.nn.Linear(in_features=int(NUM_ATOMS)*(int(ATOM_DIM)+5*NUM_ATOMS), out_features=int(NUM_ATOMS)*(int(ATOM_DIM)+5*NUM_ATOMS)),\n",
    "            torch.nn.Linear(in_features=int(NUM_ATOMS)*(int(ATOM_DIM)+5*NUM_ATOMS), out_features=int(NUM_ATOMS)*(int(ATOM_DIM)+5*NUM_ATOMS)),\n",
    "            torch.nn.Linear(in_features=int(NUM_ATOMS)*(int(ATOM_DIM)+5*NUM_ATOMS), out_features=int(NUM_ATOMS)*(int(ATOM_DIM)+5*NUM_ATOMS)),\n",
    "            torch.nn.Linear(in_features=int(NUM_ATOMS)*(int(ATOM_DIM)+5*NUM_ATOMS), out_features=int(NUM_ATOMS)*(int(ATOM_DIM)+5*NUM_ATOMS)),\n",
    "            torch.nn.Linear(in_features=int(NUM_ATOMS)*(int(ATOM_DIM)+5*NUM_ATOMS), out_features=int(NUM_ATOMS)*(int(ATOM_DIM)+5*NUM_ATOMS)),\n",
    "        ]\n",
    "        self.elu = torch.nn.ELU()\n",
    "\n",
    "    def forward(self, z_latent, batch = False):\n",
    "        mol = z_latent\n",
    "        for layer in self.decoding:\n",
    "            mol = layer(mol)\n",
    "            mol = self.elu(mol)\n",
    "       \n",
    "        # reshape:\n",
    "        if batch == False:\n",
    "            mol = torch.reshape(mol, (NUM_ATOMS, ATOM_DIM + BOND_DIM*NUM_ATOMS))\n",
    "\n",
    "            mol_features = torch.clone(mol[:,:ATOM_DIM])\n",
    "            mol_features = temperature(mol_features, t=0.3)\n",
    "            mol_features = torch.softmax(mol_features, dim= 1)\n",
    "\n",
    "            mol_edges = torch.clone(mol[:,ATOM_DIM:])\n",
    "            mol_edges = torch.reshape(mol_edges, (NUM_ATOMS, NUM_ATOMS, BOND_DIM))\n",
    "            edges_T = torch.transpose_copy(mol_edges, 0, 1)\n",
    "            edges_S = (mol_edges + edges_T)*0.5\n",
    "            edges_S = temperature(edges_S, t=0.3)\n",
    "            \n",
    "            edges_S = torch.softmax(edges_S, dim= 2)\n",
    "            #edges_S =  torch.reshape(edges_S, (NUM_ATOMS, NUM_ATOMS*BOND_DIM))\n",
    "            #mol = torch.cat((mol[:,:ATOM_DIM], edges_S), 1)\n",
    "            features = mol_features\n",
    "            edge_attr = edges_S\n",
    "\n",
    "        else:\n",
    "            #mol = torch.reshape(mol, (NUM_ATOMS*BATCH_SIZE, ATOM_DIM + 5*NUM_ATOMS))\n",
    "            features = torch.Tensor(size=(0, ATOM_DIM))\n",
    "            edge_attr = torch.Tensor(size=(0, NUM_ATOMS, 5))\n",
    "            for i in range(BATCH_SIZE):\n",
    "                one_mol = torch.clone(mol[i])\n",
    "                one_mol_reshaped = torch.reshape(one_mol, (NUM_ATOMS, ATOM_DIM + BOND_DIM*NUM_ATOMS))\n",
    "                one_mol_features = torch.clone(one_mol_reshaped[:,:ATOM_DIM])\n",
    "                one_mol_features = temperature(one_mol_features, t=0.3)\n",
    "                one_mol_features = torch.softmax(one_mol_features, dim= 1)\n",
    "                \n",
    "                one_mol_edges = torch.clone(one_mol_reshaped[:,ATOM_DIM:])\n",
    "                one_mol_edges = torch.reshape(one_mol_edges, (NUM_ATOMS, NUM_ATOMS, BOND_DIM))\n",
    "                edges_T = torch.transpose_copy(one_mol_edges, 0, 1)\n",
    "                edges_S = (one_mol_edges + edges_T)*0.5\n",
    "                edges_S = torch.softmax(edges_S, dim= 2) # dim 1 ?\n",
    "                #edges_S =  torch.reshape(edges_S, (NUM_ATOMS, NUM_ATOMS*BOND_DIM))\n",
    "                #mol_to_cat = torch.cat((one_mol_features, edges_S), 1)\n",
    "                features = torch.cat((features, one_mol_features), 0)\n",
    "                edge_attr = torch.cat((edge_attr, edges_S), 0)\n",
    "            \n",
    "\n",
    "        return features, edge_attr\n",
    "    \n",
    "\n",
    "    def loss():\n",
    "        pass\n",
    "\n",
    " \n",
    "\n",
    "class GraphNeuralNetwork(torch.nn.Module):  # TODO: assign hyperparameters to attributes and define the forward pass\n",
    "    def __init__(self, encoder, decoder, hidden_size, atom_dim = ATOM_DIM, latent_dim=LATENT_DIM):\n",
    "        super(GraphNeuralNetwork, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "\n",
    "        self.encoder = Encoder(hidden_size)\n",
    "        self.decoder = Decoder(hidden_size)\n",
    "\n",
    "        #decode edges:\n",
    "        \n",
    "    \n",
    "    def encode(self, features, edge_index, edge_attr, batch):\n",
    "        return self.encoder(features, edge_index, edge_attr, batch)\n",
    "\n",
    "    def reparametrize(self, mu, std):\n",
    "        eps = torch.randn_like(std)\n",
    "        z_reparametrized = mu + std*eps\n",
    "        return z_reparametrized\n",
    "        \n",
    "\n",
    "    def decode(self, z_latent, batch = False):\n",
    "        return self.decoder(z_latent, batch)\n",
    "\n",
    "    def forward(self, features, adj, edge_attr, batch):\n",
    "        mu, std = self.encode(features, adj, edge_attr, batch)\n",
    "        z = self.reparametrize(mu, std)\n",
    "        batch = True if len(batch)>32 else False\n",
    "        nodes_dec, edges_dec, edges_attr_dec = self.decode(z, batch)\n",
    "\n",
    "        return nodes_dec, edges_dec, edges_attr_dec\n",
    "    \n",
    "\n",
    "    # def eval(self, test_data_loader):\n",
    "    #     loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    #     loop = tqdm(enumerate(train_loader))\n",
    "    #     for i, data in loop:\n",
    "    #         data = data.to(device)\n",
    "\n",
    "    #         real_features, real_edge_index, real_edge_attr, batch, mol = data.features, data.edge_index.to(dtype=torch.int64), data.edge_attr, data.batch, data.mol\n",
    "    #         mu, std = self.encode(real_features, real_edge_index, real_edge_attr, batch)\n",
    "    #         z_reparametrized = self.reparametrize(mu, std)\n",
    "\n",
    "    #         features_decoded, edges_decoded, edges_attr_decoded = self.decode(z_reparametrized, batch=True)\n",
    "                \n",
    "    #         real_adj_edges, real_adj_edge_attr = batch_edge_idx_to_adj(real_edge_index, real_edge_attr)\n",
    "\n",
    "    #         features_loss = loss_fn(one_hot(torch.argmax(features_decoded, dim=1), num_classes = ATOM_DIM).to(torch.float64), real_features)\n",
    "    #         edges_loss = loss_fn(edges_decoded, real_adj_edges)\n",
    "    #         edges_attr_loss = loss_fn(one_hot(torch.argmax(edges_attr_decoded, dim=2), num_classes = BOND_DIM).to(torch.float64), real_adj_edge_attr)\n",
    "\n",
    "    #         reconstruction_loss = features_loss + edges_loss + edges_attr_loss\n",
    "    #         kl_div = -torch.sum(1 + torch.log(std.pow(2)) - mu.pow(2) - std.pow(2))\n",
    "    #         loss = 5*reconstruction_loss + kl_div\n",
    "    #         print(\"feat, edges, edges_attr, kl \", features_loss, edges_loss, edges_attr_loss, kl_div)\n",
    "    #         print(\"total \", loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(hidden_size=HIDDEN_SIZE)\n",
    "decoder = Encoder(hidden_size=HIDDEN_SIZE)\n",
    "\n",
    "encoder=encoder.float()\n",
    "decoder = decoder.float()\n",
    "g = GraphNeuralNetwork(hidden_size=512, encoder=encoder, decoder=decoder)\n",
    "#g=g.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import int64\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "def train(model, train_loader, valid_loader, l_r = 0.00001, epochs = 1000):\n",
    "        learning_rate = l_r\n",
    "        #entropy_fn = torch.nn.Entropy() # TODO <- for delete uncertainity\n",
    "        optimizer = torch.optim.Adam(params=model.parameters(), lr= learning_rate)\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        for epoch in trange(1, epochs + 1, leave=False):\n",
    "            loop = tqdm(enumerate(train_loader))\n",
    "            for i, data in loop:\n",
    "                data = data.to(device)\n",
    "                if data.features.shape[0] < BATCH_SIZE*NUM_ATOMS: break\n",
    "                real_features, real_edge_index, real_edge_attr, batch, mol = data.features, data.edge_index.to(dtype=torch.int64), data.edge_attr, data.batch, data.mol\n",
    "                \n",
    "                mu, std = model.encode(real_features, real_edge_index, real_edge_attr, batch)\n",
    "                z_reparametrized = model.reparametrize(mu, std)\n",
    "\n",
    "                features_decoded, edges_attr_decoded = model.decode(z_reparametrized, batch=True)\n",
    "                real_adj_edges, real_adj_edge_attr = batch_edge_idx_to_adj(real_edge_index, real_edge_attr)\n",
    "                print(features_decoded.shape, real_features.shape)\n",
    "                features_loss = loss_fn(features_decoded, real_features[:, :ATOM_DIM])\n",
    "                #edges_loss = loss_fn(edges_decoded, real_adj_edges)\n",
    "                edges_attr_loss = loss_fn(edges_attr_decoded, real_adj_edge_attr)\n",
    "\n",
    "                reconstruction_loss = features_loss + edges_attr_loss\n",
    "                kl_div = -torch.sum(1 + torch.log(std.pow(2)) - mu.pow(2) - std.pow(2))\n",
    "                loss = 5*reconstruction_loss + kl_div\n",
    "                print(loss)\n",
    "                loss.backward()\n",
    "                optimizer.step() \n",
    "                optimizer.zero_grad()\n",
    "                model.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c651c2edfcf414ebdead3161476f8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 12]) torch.Size([32, 32]) torch.Size([32, 32, 5])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "\n",
    "loop = tqdm(enumerate(val_loader))\n",
    "for i, data in loop:\n",
    "    if i > 0:\n",
    "        break\n",
    "\n",
    "    real_features, real_edge_index, real_edge_attr, batch, mol = data.features, data.edge_index.to(dtype=torch.int64), data.edge_attr, data.batch, data.mol\n",
    "    mu, std = g.encode(real_features, real_edge_index, real_edge_attr, batch)\n",
    "    z_reparametrized = g.reparametrize(mu, std)\n",
    "    features_decoded, edges_attr_decoded = g.decode(z_reparametrized, batch = True)\n",
    "    f, e, e_a = features_decoded[:32], edges_attr_decoded[:32]\n",
    "    f = one_hot(torch.argmax(f, dim=1), num_classes = ATOM_DIM).to(torch.float64)\n",
    "    e_a = one_hot(torch.argmax(e_a, dim=2), num_classes = BOND_DIM).to(torch.float64)\n",
    "    print(f.size(), e.size(), e_a.size())\n",
    "    mol = graph_to_molecule((f, e, e_a))\n",
    "    mol = Chem.rdchem.Mol(mol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x2f90aea90>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = graph_to_molecule((f, e, e_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=300x300>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Draw.MolToImage(mol) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fedc4bc55b394bdcb386e524448ebf68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482dcf674e104659a22987e710b2ba6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(645.2128, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(678.2071, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(658.9214, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(649.7248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(638.3267, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(651.7459, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(602.3470, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(647.2584, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(645.8186, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(631.7641, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(599.3815, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(594.6025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(609.0670, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(625.4405, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(619.3758, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(634.4954, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(642.1504, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(636.5908, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(595.7527, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(626.6285, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(669.5463, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(586.7781, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(620.2303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(616.6465, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(608.3983, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(675.5652, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(596.5924, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(688.8980, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(598.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(685.6300, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e232c7a360842e9bf96a7d6bac0e71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(645.1719, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(677.4279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(657.5870, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(648.8908, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(637.9448, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(651.9714, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(602.2819, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(647.4409, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(646.0621, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(632.0726, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(598.7628, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(594.0627, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(609.4188, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(626.2496, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(619.4477, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(633.8768, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(641.1609, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(635.1239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(595.4708, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(626.8143, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(668.8765, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(587.0520, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(620.5010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(616.3000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(608.0636, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(674.9959, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(596.7488, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(688.8057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(598.0284, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(685.2323, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95cd274fbd564a83aeb61f6a7d56a195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(644.9498, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(677.6658, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(657.5338, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(649.0898, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(637.8239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(652.1623, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(602.1717, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(647.3228, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(645.7429, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(632.0351, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(598.5323, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(594.1423, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(609.2767, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(626.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(619.3666, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(633.9249, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(641.4031, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(635.5485, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(595.4435, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(626.7721, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(669.0197, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(586.9587, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(620.3263, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(616.3935, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(607.9442, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(674.8974, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(596.7056, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(688.7846, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(597.9522, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(685.2087, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eef1ad733c243cc9fd546904cb876a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(644.8286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(677.6309, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(657.4721, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(649.0218, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(637.8447, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(652.0508, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(602.1202, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(647.2677, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(645.7410, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(631.9971, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(598.5583, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(594.0900, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(609.2355, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(625.9804, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(619.3226, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(633.8558, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(641.2945, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(635.4307, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(595.3886, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(626.7173, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(668.9368, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(586.9215, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(620.3012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(616.3071, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(607.9180, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(674.8593, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(596.6581, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(688.7371, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(597.8977, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(685.1106, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19448507c62041d99d5456a33aea1df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(644.8278, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(677.5989, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(657.4360, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(648.9825, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(637.7856, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(652.0125, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(602.0721, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(647.2221, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(645.6881, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(631.9548, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(598.5016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(594.0447, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(609.1947, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(625.9307, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(619.2652, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(633.8089, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(641.2541, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(635.4158, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(595.3421, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(626.6693, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(668.8999, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(586.8722, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(620.2423, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(616.2611, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(607.8694, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(674.8083, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(596.6101, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(688.6831, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(597.8408, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(685.0425, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb31205a0ba14bc4bae908a65eb1002e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(644.7904, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(677.5634, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(657.3889, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(648.9315, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(637.7448, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(651.9593, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(602.0220, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(647.1712, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(645.6445, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(631.9131, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(598.4657, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(593.9964, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(609.1497, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(625.8807, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(619.2178, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(633.7601, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(641.2046, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(635.3758, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(595.2903, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(626.6172, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(668.8510, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(586.8249, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(620.1915, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(616.2107, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(607.8198, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(674.7523, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(596.5628, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(688.6342, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(597.7893, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(684.9698, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83dad39d257a4ed58762e01d56ac6f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(644.7541, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(677.5198, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(657.3457, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(648.8868, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(637.6986, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(651.9095, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(601.9757, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(647.1249, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(645.5955, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(631.8716, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(598.4210, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(593.9470, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(609.1036, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(625.8268, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(619.1657, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(633.7105, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(641.1556, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(635.3390, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(595.2402, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(626.5654, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(668.8011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(586.7728, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(620.1379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(616.1608, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(607.7656, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(674.6982, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(596.5135, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(688.5788, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(597.7352, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(684.9030, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "385dfe95a0e24c0f9e0f8a005f4c5980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(644.7137, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(677.4777, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(657.3019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(648.8394, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(637.6503, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(651.8591, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(601.9222, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(647.0716, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(645.5470, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(631.8278, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(598.3776, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(593.8991, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(609.0624, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(625.7754, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([1024, 12]) torch.Size([1024, 44])\n",
      "tensor(619.1143, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train(g, train_loader=train_loader, valid_loader=val_loader, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wykres latent space po logP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.63651417] 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import entropy\n",
    "v = [[0.0,1.0],[0.5,0.5]]\n",
    "w = [0.5]\n",
    "z = [0.1]\n",
    "\n",
    "print(entropy(v), entropy(w), entropy(z))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldd23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
